<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>D14-012 â€” Replication and Reproducibility Standards - holm.chat</title>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { font-family: Georgia, serif; line-height: 1.6; color: #222; display: flex; min-height: 100vh; }

    /* Sidebar */
    .sidebar { width: 260px; min-width: 260px; background: #1a1a2e; color: #ccc; height: 100vh; position: fixed; top: 0; left: 0; overflow-y: auto; z-index: 100; transition: transform 0.2s; }
    .sidebar-header { padding: 1em; border-bottom: 1px solid #333; display: flex; justify-content: space-between; align-items: center; }
    .home-link { color: #fff; text-decoration: none; font-weight: bold; font-size: 1.1em; }
    .sidebar-toggle { background: none; border: none; color: #888; font-size: 1.4em; cursor: pointer; display: none; }
    .sidebar-content { padding: 0.5em 0; }
    .sidebar details { border-bottom: 1px solid #2a2a4a; }
    .sidebar summary { padding: 0.6em 1em; cursor: pointer; font-size: 0.85em; font-weight: bold; color: #aaa; text-transform: uppercase; letter-spacing: 0.03em; }
    .sidebar summary:hover { color: #fff; background: #2a2a4a; }
    .sidebar ul { list-style: none; padding: 0 0 0.4em 0; }
    .sidebar li { font-size: 0.82em; }
    .sidebar li a { display: block; padding: 0.3em 1em 0.3em 1.8em; color: #bbb; text-decoration: none; }
    .sidebar li a:hover { color: #fff; background: #2a2a4a; }
    .sidebar li.active a { color: #fff; background: #16213e; border-left: 3px solid #4a90d9; padding-left: calc(1.8em - 3px); }

    /* Main content */
    main { margin-left: 260px; flex: 1; max-width: 52em; padding: 2em 2em 4em 2em; }
    .mobile-menu-btn { display: none; position: fixed; top: 0.6em; left: 0.6em; z-index: 200; background: #1a1a2e; color: #fff; border: none; padding: 0.4em 0.7em; font-size: 1.2em; cursor: pointer; border-radius: 4px; }

    /* Typography */
    h1 { border-bottom: 2px solid #333; padding-bottom: 0.3em; margin-bottom: 0.8em; font-size: 1.6em; }
    h2 { border-bottom: 1px solid #ddd; padding-bottom: 0.2em; margin-top: 2em; margin-bottom: 0.6em; font-size: 1.25em; }
    h3 { margin-top: 1.5em; margin-bottom: 0.4em; }
    p { margin-bottom: 0.8em; }
    section { margin-bottom: 2em; }
    ul, ol { margin: 0.5em 0 0.8em 1.5em; }
    li { margin-bottom: 0.3em; }
    aside.metadata { background: #f8f8f8; border-left: 3px solid #666; padding: 0.8em 1.2em; margin: 1em 0; font-size: 0.9em; }
    aside.metadata dl { margin: 0; }
    aside.metadata dt { font-weight: bold; display: inline; }
    aside.metadata dt::after { content: ": "; }
    aside.metadata dd { display: inline; margin: 0; }
    aside.metadata dd::after { content: "\A"; white-space: pre; }
    table { border-collapse: collapse; width: 100%; margin: 1em 0; font-size: 0.9em; }
    th, td { border: 1px solid #ccc; padding: 0.5em; text-align: left; }
    th { background: #f0f0f0; }
    pre { background: #f5f5f5; padding: 1em; overflow-x: auto; border: 1px solid #ddd; margin: 0.8em 0; }
    code { font-family: "Courier New", monospace; font-size: 0.9em; }
    blockquote { border-left: 3px solid #999; margin: 0.8em 0; padding-left: 1em; color: #555; }

    /* Mobile */
    @media (max-width: 800px) {
        .sidebar { transform: translateX(-100%); }
        .sidebar-toggle { display: block; }
        body:not(.sidebar-closed) .sidebar { transform: translateX(-100%); }
        body.sidebar-open .sidebar { transform: translateX(0); }
        main { margin-left: 0; padding: 3em 1em 2em 1em; }
        .mobile-menu-btn { display: block; }
    }

  </style>
</head>
<body>
<button class="mobile-menu-btn" onclick="document.body.classList.toggle('sidebar-open')">&#9776;</button>
<nav class="sidebar" id="sidebar">
  <div class="sidebar-header">
    <a href="index.html" class="home-link">holm.chat</a>
    <button class="sidebar-toggle" onclick="document.body.classList.toggle('sidebar-closed')" aria-label="Toggle menu">&times;</button>
  </div>
  <div class="sidebar-content">
  <details>
    <summary>Constitution & Philosophy</summary>
    <ul>
      <li><a href="con-001.html">CON-001</a></li>
      <li><a href="con-002.html">CON-002</a></li>
      <li><a href="con-003.html">CON-003</a></li>
      <li><a href="con-004.html">CON-004</a></li>
      <li><a href="con-005.html">CON-005</a></li>
      <li><a href="con-006.html">CON-006</a></li>
      <li><a href="con-007.html">CON-007</a></li>
      <li><a href="con-008.html">CON-008</a></li>
      <li><a href="con-009.html">CON-009</a></li>
      <li><a href="con-010.html">CON-010</a></li>
      <li><a href="con-011.html">CON-011</a></li>
      <li><a href="con-012.html">CON-012</a></li>
      <li><a href="con-013.html">CON-013</a></li>
      <li><a href="domain-1.html">DOMAIN-1</a></li>
      <li><a href="eth-001.html">ETH-001</a></li>
    </ul>
  </details>
  <details>
    <summary>Governance & Authority</summary>
    <ul>
      <li><a href="domain-2.html">DOMAIN-2</a></li>
      <li><a href="gov-001.html">GOV-001</a></li>
      <li><a href="gov-002.html">GOV-002</a></li>
      <li><a href="gov-003.html">GOV-003</a></li>
      <li><a href="gov-004.html">GOV-004</a></li>
      <li><a href="gov-005.html">GOV-005</a></li>
      <li><a href="gov-006.html">GOV-006</a></li>
      <li><a href="gov-007.html">GOV-007</a></li>
      <li><a href="gov-008.html">GOV-008</a></li>
      <li><a href="gov-009.html">GOV-009</a></li>
      <li><a href="gov-010.html">GOV-010</a></li>
      <li><a href="gov-011.html">GOV-011</a></li>
      <li><a href="gov-012.html">GOV-012</a></li>
      <li><a href="gov-013.html">GOV-013</a></li>
      <li><a href="gov-014.html">GOV-014</a></li>
    </ul>
  </details>
  <details>
    <summary>Security & Integrity</summary>
    <ul>
      <li><a href="domain-3.html">DOMAIN-3</a></li>
      <li><a href="sec-001.html">SEC-001</a></li>
      <li><a href="sec-002.html">SEC-002</a></li>
      <li><a href="sec-003.html">SEC-003</a></li>
      <li><a href="sec-004.html">SEC-004</a></li>
      <li><a href="sec-005.html">SEC-005</a></li>
      <li><a href="sec-006.html">SEC-006</a></li>
      <li><a href="sec-007.html">SEC-007</a></li>
      <li><a href="sec-008.html">SEC-008</a></li>
      <li><a href="sec-009.html">SEC-009</a></li>
      <li><a href="sec-010.html">SEC-010</a></li>
      <li><a href="sec-011.html">SEC-011</a></li>
      <li><a href="sec-012.html">SEC-012</a></li>
      <li><a href="sec-013.html">SEC-013</a></li>
      <li><a href="sec-014.html">SEC-014</a></li>
    </ul>
  </details>
  <details>
    <summary>Infrastructure & Power</summary>
    <ul>
      <li><a href="d4-001.html">D4-001</a></li>
      <li><a href="d4-002.html">D4-002</a></li>
      <li><a href="d4-003.html">D4-003</a></li>
      <li><a href="d4-004.html">D4-004</a></li>
      <li><a href="d4-005.html">D4-005</a></li>
      <li><a href="d4-006.html">D4-006</a></li>
      <li><a href="d4-007.html">D4-007</a></li>
      <li><a href="d4-008.html">D4-008</a></li>
      <li><a href="d4-009.html">D4-009</a></li>
      <li><a href="d4-010.html">D4-010</a></li>
      <li><a href="d4-011.html">D4-011</a></li>
      <li><a href="d4-012.html">D4-012</a></li>
      <li><a href="d4-013.html">D4-013</a></li>
      <li><a href="d4-014.html">D4-014</a></li>
      <li><a href="domain-4.html">DOMAIN-4</a></li>
    </ul>
  </details>
  <details>
    <summary>Platform & Core Systems</summary>
    <ul>
      <li><a href="d5-001.html">D5-001</a></li>
      <li><a href="d5-002.html">D5-002</a></li>
      <li><a href="d5-003.html">D5-003</a></li>
      <li><a href="d5-004.html">D5-004</a></li>
      <li><a href="d5-005.html">D5-005</a></li>
      <li><a href="d5-006.html">D5-006</a></li>
      <li><a href="domain-5.html">DOMAIN-5</a></li>
    </ul>
  </details>
  <details>
    <summary>Data & Archives</summary>
    <ul>
      <li><a href="d6-001.html">D6-001</a></li>
      <li><a href="d6-002.html">D6-002</a></li>
      <li><a href="d6-003.html">D6-003</a></li>
      <li><a href="d6-004.html">D6-004</a></li>
      <li><a href="d6-005.html">D6-005</a></li>
      <li><a href="d6-006.html">D6-006</a></li>
      <li><a href="d6-007.html">D6-007</a></li>
      <li><a href="d6-008.html">D6-008</a></li>
      <li><a href="d6-009.html">D6-009</a></li>
      <li><a href="d6-010.html">D6-010</a></li>
      <li><a href="d6-011.html">D6-011</a></li>
      <li><a href="d6-012.html">D6-012</a></li>
      <li><a href="d6-013.html">D6-013</a></li>
      <li><a href="d6-014.html">D6-014</a></li>
      <li><a href="d6-015.html">D6-015</a></li>
      <li><a href="domain-6.html">DOMAIN-6</a></li>
    </ul>
  </details>
  <details>
    <summary>Intelligence & Analysis</summary>
    <ul>
      <li><a href="d7-001.html">D7-001</a></li>
      <li><a href="d7-002.html">D7-002</a></li>
      <li><a href="d7-003.html">D7-003</a></li>
      <li><a href="d7-004.html">D7-004</a></li>
      <li><a href="d7-005.html">D7-005</a></li>
      <li><a href="d7-006.html">D7-006</a></li>
      <li><a href="d7-007.html">D7-007</a></li>
      <li><a href="d7-008.html">D7-008</a></li>
      <li><a href="d7-009.html">D7-009</a></li>
      <li><a href="d7-010.html">D7-010</a></li>
      <li><a href="d7-011.html">D7-011</a></li>
      <li><a href="d7-012.html">D7-012</a></li>
      <li><a href="d7-013.html">D7-013</a></li>
      <li><a href="domain-7.html">DOMAIN-7</a></li>
    </ul>
  </details>
  <details>
    <summary>Automation & Agents</summary>
    <ul>
      <li><a href="d8-001.html">D8-001</a></li>
      <li><a href="d8-002.html">D8-002</a></li>
      <li><a href="d8-003.html">D8-003</a></li>
      <li><a href="d8-004.html">D8-004</a></li>
      <li><a href="d8-005.html">D8-005</a></li>
      <li><a href="d8-006.html">D8-006</a></li>
      <li><a href="d8-007.html">D8-007</a></li>
      <li><a href="d8-008.html">D8-008</a></li>
      <li><a href="d8-009.html">D8-009</a></li>
      <li><a href="d8-010.html">D8-010</a></li>
      <li><a href="d8-011.html">D8-011</a></li>
      <li><a href="d8-012.html">D8-012</a></li>
      <li><a href="d8-013.html">D8-013</a></li>
      <li><a href="domain-8.html">DOMAIN-8</a></li>
    </ul>
  </details>
  <details>
    <summary>Education & Training</summary>
    <ul>
      <li><a href="d9-001.html">D9-001</a></li>
      <li><a href="d9-002.html">D9-002</a></li>
      <li><a href="d9-003.html">D9-003</a></li>
      <li><a href="d9-004.html">D9-004</a></li>
      <li><a href="d9-005.html">D9-005</a></li>
      <li><a href="d9-006.html">D9-006</a></li>
      <li><a href="d9-007.html">D9-007</a></li>
      <li><a href="d9-008.html">D9-008</a></li>
      <li><a href="d9-009.html">D9-009</a></li>
      <li><a href="d9-010.html">D9-010</a></li>
      <li><a href="d9-011.html">D9-011</a></li>
      <li><a href="d9-012.html">D9-012</a></li>
      <li><a href="d9-013.html">D9-013</a></li>
      <li><a href="domain-9.html">DOMAIN-9</a></li>
    </ul>
  </details>
  <details>
    <summary>User Operations</summary>
    <ul>
      <li><a href="d10-002.html">D10-002</a></li>
      <li><a href="d10-003.html">D10-003</a></li>
      <li><a href="d10-004.html">D10-004</a></li>
      <li><a href="d10-005.html">D10-005</a></li>
      <li><a href="d10-006.html">D10-006</a></li>
      <li><a href="d10-007.html">D10-007</a></li>
      <li><a href="d10-008.html">D10-008</a></li>
      <li><a href="d10-009.html">D10-009</a></li>
      <li><a href="d10-010.html">D10-010</a></li>
      <li><a href="d10-011.html">D10-011</a></li>
      <li><a href="d10-012.html">D10-012</a></li>
      <li><a href="d10-013.html">D10-013</a></li>
      <li><a href="d10-014.html">D10-014</a></li>
      <li><a href="domain-10.html">DOMAIN-10</a></li>
      <li><a href="ops-001.html">OPS-001</a></li>
    </ul>
  </details>
  <details>
    <summary>Administration</summary>
    <ul>
      <li><a href="d11-001.html">D11-001</a></li>
      <li><a href="d11-002.html">D11-002</a></li>
      <li><a href="d11-003.html">D11-003</a></li>
      <li><a href="d11-004.html">D11-004</a></li>
      <li><a href="d11-005.html">D11-005</a></li>
      <li><a href="d11-006.html">D11-006</a></li>
      <li><a href="d11-007.html">D11-007</a></li>
      <li><a href="d11-008.html">D11-008</a></li>
      <li><a href="d11-009.html">D11-009</a></li>
      <li><a href="d11-010.html">D11-010</a></li>
      <li><a href="d11-011.html">D11-011</a></li>
      <li><a href="d11-012.html">D11-012</a></li>
      <li><a href="d11-013.html">D11-013</a></li>
      <li><a href="domain-11.html">DOMAIN-11</a></li>
    </ul>
  </details>
  <details>
    <summary>Disaster Recovery</summary>
    <ul>
      <li><a href="d12-001.html">D12-001</a></li>
      <li><a href="d12-002.html">D12-002</a></li>
      <li><a href="d12-003.html">D12-003</a></li>
      <li><a href="d12-004.html">D12-004</a></li>
      <li><a href="d12-005.html">D12-005</a></li>
      <li><a href="d12-006.html">D12-006</a></li>
      <li><a href="d12-007.html">D12-007</a></li>
      <li><a href="d12-008.html">D12-008</a></li>
      <li><a href="d12-009.html">D12-009</a></li>
      <li><a href="d12-010.html">D12-010</a></li>
      <li><a href="d12-011.html">D12-011</a></li>
      <li><a href="d12-012.html">D12-012</a></li>
      <li><a href="d12-013.html">D12-013</a></li>
      <li><a href="d12-014.html">D12-014</a></li>
      <li><a href="domain-12.html">DOMAIN-12</a></li>
    </ul>
  </details>
  <details>
    <summary>Evolution & Adaptation</summary>
    <ul>
      <li><a href="d13-001.html">D13-001</a></li>
      <li><a href="d13-002.html">D13-002</a></li>
      <li><a href="d13-003.html">D13-003</a></li>
      <li><a href="d13-004.html">D13-004</a></li>
      <li><a href="d13-005.html">D13-005</a></li>
      <li><a href="d13-006.html">D13-006</a></li>
      <li><a href="d13-007.html">D13-007</a></li>
      <li><a href="d13-008.html">D13-008</a></li>
      <li><a href="d13-009.html">D13-009</a></li>
      <li><a href="d13-010.html">D13-010</a></li>
      <li><a href="d13-011.html">D13-011</a></li>
      <li><a href="d13-012.html">D13-012</a></li>
      <li><a href="d13-013.html">D13-013</a></li>
      <li><a href="domain-13.html">DOMAIN-13</a></li>
    </ul>
  </details>
  <details open>
    <summary>Research & Theory</summary>
    <ul>
      <li><a href="d14-001.html">D14-001</a></li>
      <li><a href="d14-002.html">D14-002</a></li>
      <li><a href="d14-003.html">D14-003</a></li>
      <li><a href="d14-004.html">D14-004</a></li>
      <li><a href="d14-005.html">D14-005</a></li>
      <li><a href="d14-006.html">D14-006</a></li>
      <li><a href="d14-007.html">D14-007</a></li>
      <li><a href="d14-008.html">D14-008</a></li>
      <li><a href="d14-009.html">D14-009</a></li>
      <li><a href="d14-010.html">D14-010</a></li>
      <li><a href="d14-011.html">D14-011</a></li>
      <li class="active"><a href="d14-012.html">D14-012</a></li>
      <li><a href="d14-013.html">D14-013</a></li>
      <li><a href="domain-14.html">DOMAIN-14</a></li>
    </ul>
  </details>
  <details>
    <summary>Ethics & Safeguards</summary>
    <ul>
      <li><a href="d15-001.html">D15-001</a></li>
      <li><a href="d15-002.html">D15-002</a></li>
      <li><a href="d15-003.html">D15-003</a></li>
      <li><a href="d15-004.html">D15-004</a></li>
      <li><a href="d15-005.html">D15-005</a></li>
      <li><a href="domain-15.html">DOMAIN-15</a></li>
    </ul>
  </details>
  <details>
    <summary>Interface & Navigation</summary>
    <ul>
      <li><a href="d16-001.html">D16-001</a></li>
      <li><a href="d16-002.html">D16-002</a></li>
      <li><a href="d16-003.html">D16-003</a></li>
      <li><a href="d16-004.html">D16-004</a></li>
      <li><a href="d16-005.html">D16-005</a></li>
      <li><a href="d16-006.html">D16-006</a></li>
      <li><a href="d16-007.html">D16-007</a></li>
      <li><a href="d16-008.html">D16-008</a></li>
      <li><a href="d16-009.html">D16-009</a></li>
      <li><a href="d16-010.html">D16-010</a></li>
      <li><a href="d16-011.html">D16-011</a></li>
      <li><a href="d16-012.html">D16-012</a></li>
      <li><a href="d16-013.html">D16-013</a></li>
      <li><a href="d16-014.html">D16-014</a></li>
    </ul>
  </details>
  <details>
    <summary>Scaling & Federation</summary>
    <ul>
      <li><a href="d17-001.html">D17-001</a></li>
      <li><a href="d17-002.html">D17-002</a></li>
      <li><a href="d17-003.html">D17-003</a></li>
      <li><a href="d17-004.html">D17-004</a></li>
      <li><a href="d17-005.html">D17-005</a></li>
      <li><a href="d17-006.html">D17-006</a></li>
      <li><a href="d17-007.html">D17-007</a></li>
      <li><a href="d17-008.html">D17-008</a></li>
      <li><a href="d17-009.html">D17-009</a></li>
      <li><a href="d17-010.html">D17-010</a></li>
      <li><a href="d17-011.html">D17-011</a></li>
      <li><a href="d17-012.html">D17-012</a></li>
      <li><a href="d17-013.html">D17-013</a></li>
      <li><a href="d17-014.html">D17-014</a></li>
      <li><a href="d17-015.html">D17-015</a></li>
    </ul>
  </details>
  <details>
    <summary>Import & Quarantine</summary>
    <ul>
      <li><a href="d18-001.html">D18-001</a></li>
      <li><a href="d18-002.html">D18-002</a></li>
      <li><a href="d18-003.html">D18-003</a></li>
      <li><a href="d18-004.html">D18-004</a></li>
      <li><a href="d18-005.html">D18-005</a></li>
      <li><a href="d18-006.html">D18-006</a></li>
      <li><a href="d18-007.html">D18-007</a></li>
      <li><a href="d18-008.html">D18-008</a></li>
      <li><a href="d18-009.html">D18-009</a></li>
      <li><a href="d18-010.html">D18-010</a></li>
      <li><a href="d18-011.html">D18-011</a></li>
      <li><a href="d18-012.html">D18-012</a></li>
      <li><a href="d18-013.html">D18-013</a></li>
      <li><a href="d18-014.html">D18-014</a></li>
    </ul>
  </details>
  <details>
    <summary>Quality Assurance</summary>
    <ul>
      <li><a href="d19-001.html">D19-001</a></li>
      <li><a href="d19-002.html">D19-002</a></li>
      <li><a href="d19-003.html">D19-003</a></li>
      <li><a href="d19-004.html">D19-004</a></li>
      <li><a href="d19-005.html">D19-005</a></li>
      <li><a href="d19-006.html">D19-006</a></li>
      <li><a href="d19-007.html">D19-007</a></li>
      <li><a href="d19-008.html">D19-008</a></li>
      <li><a href="d19-009.html">D19-009</a></li>
      <li><a href="d19-010.html">D19-010</a></li>
      <li><a href="d19-011.html">D19-011</a></li>
      <li><a href="d19-012.html">D19-012</a></li>
      <li><a href="d19-013.html">D19-013</a></li>
      <li><a href="d19-014.html">D19-014</a></li>
      <li><a href="d19-015.html">D19-015</a></li>
    </ul>
  </details>
  <details>
    <summary>Institutional Memory</summary>
    <ul>
      <li><a href="d20-001.html">D20-001</a></li>
      <li><a href="d20-002.html">D20-002</a></li>
      <li><a href="d20-003.html">D20-003</a></li>
      <li><a href="d20-004.html">D20-004</a></li>
      <li><a href="d20-005.html">D20-005</a></li>
      <li><a href="d20-006.html">D20-006</a></li>
      <li><a href="d20-007.html">D20-007</a></li>
      <li><a href="d20-008.html">D20-008</a></li>
      <li><a href="d20-009.html">D20-009</a></li>
      <li><a href="d20-010.html">D20-010</a></li>
      <li><a href="d20-011.html">D20-011</a></li>
      <li><a href="d20-012.html">D20-012</a></li>
      <li><a href="d20-013.html">D20-013</a></li>
    </ul>
  </details>
  <details>
    <summary>Meta-Documentation</summary>
    <ul>
      <li><a href="meta-001.html">META-001</a></li>
      <li><a href="meta-002.html">META-002</a></li>
      <li><a href="meta-003.html">META-003</a></li>
      <li><a href="meta-004.html">META-004</a></li>
      <li><a href="meta-005.html">META-005</a></li>
      <li><a href="meta-006.html">META-006</a></li>
      <li><a href="meta-007.html">META-007</a></li>
      <li><a href="meta-008.html">META-008</a></li>
      <li><a href="meta-009.html">META-009</a></li>
      <li><a href="meta-010.html">META-010</a></li>
      <li><a href="meta-011.html">META-011</a></li>
      <li><a href="meta-012.html">META-012</a></li>
      <li><a href="meta-013.html">META-013</a></li>
      <li><a href="meta-014.html">META-014</a></li>
      <li><a href="meta-015.html">META-015</a></li>
      <li><a href="meta-framework.html">Unifying Standards for the Hol</a></li>
    </ul>
  </details>
  <details>
    <summary>Framework</summary>
    <ul>
      <li><a href="appendix-a.html">ARTICLE INDEX (ALL DOMAINS)</a></li>
      <li><a href="appendix-a-2.html">ARTICLE TEMPLATE (FULL)</a></li>
      <li><a href="appendix-b.html">DOCUMENT VERSIONING SCHEME</a></li>
      <li><a href="appendix-b-2.html">META-RULES FOR ALL DOCUMENTATI</a></li>
      <li><a href="appendix-c.html">HOW TO USE THIS FRAMEWORK</a></li>
      <li><a href="consolidated-writing-schedule.html">Consolidated Writing Schedule</a></li>
      <li><a href="cross-domain-integration.html">CROSS-DOMAIN INTEGRATION</a></li>
      <li><a href="cross-domain-integration-2.html">CROSS-DOMAIN INTEGRATION</a></li>
      <li><a href="cross-domain-dependency-matrix.html">Cross-Domain Dependency Matrix</a></li>
      <li><a href="cross-domain-synthesis-domains-6-10.html">CROSS-DOMAIN SYNTHESIS: DOMAIN</a></li>
      <li><a href="universal-review-process.html">UNIVERSAL REVIEW PROCESS</a></li>
      <li><a href="universal-maintenance-plan.html">UNIVERSAL MAINTENANCE PLAN</a></li>
    </ul>
  </details>
  </div>
</nav>

<main>
<article id="d14-012">
  <h1>D14-012 &mdash; Replication and Reproducibility Standards</h1>
<aside class="metadata">
<dl>
  <dt>Document ID</dt>
  <dd>D14-012</dd>
  <dt>Domain</dt>
  <dd>14 -- Research & Theory</dd>
  <dt>Version</dt>
  <dd>1.0.0</dd>
  <dt>Date</dt>
  <dd>2026-02-17</dd>
  <dt>Status</dt>
  <dd>Ratified</dd>
  <dt>Depends On</dt>
  <dd>ETH-001, CON-001, D14-001, D14-002, D14-004, D14-008</dd>
  <dt>Depended Upon By</dt>
  <dd>D14-009 (replication as validation method). All Domain 14 articles that produce findings requiring verified confidence levels. Referenced by all domains that depend on verified research findings.</dd>
</dl>
</aside>

<section>
<h2>Purpose</h2>

<p>This article defines the standards for replicating and reproducing research results within the institution. Replication -- the independent reproduction of a result -- is the gold standard of scientific validation. In a conventional research community, replication means a different researcher, in a different laboratory, using the same method, obtains the same result. This provides strong evidence that the result reflects reality rather than the idiosyncrasies of one researcher's equipment, methodology, or biases.</p>
<p>This institution cannot achieve conventional replication. The same person, using the same equipment, in the same environment, will produce results that are correlated with the original investigation regardless of how much time has passed. D14-001 acknowledges this limitation honestly and introduces four adapted replication methods: temporal, methodological, environmental, and documentation-based. This article provides the detailed standards and procedures for each method, defines what constitutes a successful replication, and establishes how replication results affect the confidence classification of the original finding.</p>
<p>The purpose is not to pretend that adapted replication is as powerful as independent replication. It is not. The purpose is to extract the maximum possible confidence from the replication methods available to a solo institution, while being explicit about where those methods fall short.</p>
</section>

<section>
<h2>Scope</h2>

<p><strong>In scope:</strong>
- Definitions and standards for the four adapted replication methods.
- Criteria for what constitutes a successful replication.
- Criteria for what constitutes a replication failure and how to handle it.
- The Replication Record: documentation format for replication attempts.
- Replication scheduling: when and how often findings should be replicated.
- The relationship between replication and the confidence classification system (D14-004).
- Honest assessment of the limitations of adapted replication.</p>
<p><strong>Out of scope:</strong>
- General experimental methodology (D14-002, though replications follow that methodology).
- The philosophical justification for replication (D14-001, Section 4.3).
- Data integrity procedures for replication data (D14-008).
- General validation and review procedures (D14-009).</p>
</section>

<section>
<h2>Background</h2>

<h3>3.1 The Replication Crisis and Its Lessons</h3>
<p>The broader scientific community has discovered, to its discomfort, that many published findings do not replicate. This "replication crisis" has affected fields from psychology to medicine to economics. The causes are multiple: small sample sizes, publication bias toward positive results, flexible data analysis that allows researchers to find patterns that are not real, and insufficient methodological detail to enable precise replication.</p>
<p>This institution can learn from the replication crisis without experiencing it directly. The lessons are: replication is harder than it looks; results that seem robust may not be; methodological detail matters enormously for reproducibility; and the default assumption should be that a finding requires replication, not that it does not.</p>

<h3>3.2 Adapted Replication in Context</h3>
<p>D14-001, Section 4.3 introduces the four adapted replication methods. This article provides the operational detail for each. The methods are ordered by their independence from the original investigation, from most independent to least:</p>
<p><strong>Methodological variation</strong> provides the greatest independence because a different method is used to investigate the same question. If two different methods yield the same conclusion, the agreement is unlikely to be an artifact of either method alone.</p>
<p><strong>Environmental variation</strong> provides moderate independence by changing the conditions under which the investigation is conducted. Different hardware, different software versions, different environmental conditions reduce the chance that the result is condition-specific.</p>
<p><strong>Temporal replication</strong> provides moderate independence by introducing time between the original and the replication. The operator's knowledge, skills, biases, and even the hardware's condition will have changed, providing a degree of natural variation.</p>
<p><strong>Documentation replication</strong> provides the least independence but tests the most practically relevant question: can a future operator reproduce this result using only the documentation? If the documentation is sufficient for reproduction, the finding is at least procedurally robust.</p>

<h3>3.3 When Replication Fails</h3>
<p>A replication failure -- where the replication attempt does not produce the same result as the original investigation -- is not a disaster. It is information. It tells the institution that the original finding may be condition-dependent, that the original methodology may have had an undetected flaw, or that the original result may have been a statistical anomaly. Any of these conclusions is valuable. The worst outcome is not a replication failure but an unreplicated finding treated as verified -- because that finding may be wrong, and the institution will never know.</p>
</section>

<section>
<h2>System Model</h2>

<h3>4.1 Adapted Replication Methods: Detailed Standards</h3>

<p><strong>Method 1: Temporal Replication.</strong></p>
<p>The same investigation is repeated after a significant time interval, using the same methodology and (as nearly as possible) the same equipment. The minimum interval is 6 months from the completion of the original investigation. The operator re-executes the experimental procedure from the documentation (not from memory) and compares the results against the original.</p>
<p>Standards for temporal replication:</p>
<ul>
<li>The replication must use the documented procedure, not the operator's memory of the procedure. The operator should treat the documentation as if it were written by someone else.</li>
<li>The pre-registration for the replication must reference the original experiment and state that this is a temporal replication attempt.</li>
<li>Differences in conditions between the original and the replication (hardware changes, software updates, environmental differences) must be documented. These differences may explain result variations and must not be concealed.</li>
<li>The comparison between original and replication results must use the same analysis methods.</li>
</ul>

<p><strong>Method 2: Methodological Variation.</strong></p>
<p>The same question is investigated using a fundamentally different method. If the original investigation measured filesystem reliability by counting errors during scrubs, the methodological variation might measure reliability by injecting known corruption and measuring detection rates. The question is the same; the approach is different.</p>
<p>Standards for methodological variation:</p>
<ul>
<li>The alternative method must be genuinely different, not a minor variation of the original. Changing a single parameter does not constitute methodological variation.</li>
<li>The alternative method must be independently capable of answering the same question. If the alternative method could not, in principle, reach the same conclusion as the original, it is not a valid replication method.</li>
<li>The pre-registration for the methodological variation must specify the original experiment, the alternative method, and why the alternative method is expected to answer the same question.</li>
<li>If the methods produce the same conclusion, the finding's confidence is substantially strengthened. If they produce different conclusions, the discrepancy must be investigated before either conclusion is classified above "provisional."</li>
</ul>

<p><strong>Method 3: Environmental Variation.</strong></p>
<p>The same investigation is repeated under different environmental conditions: different hardware, different software version, different time of day, different season, different system load. The purpose is to test whether the original result is robust across conditions or whether it is specific to the conditions under which it was originally observed.</p>
<p>Standards for environmental variation:</p>
<ul>
<li>The specific environmental differences must be documented. Generic statements like "different conditions" are insufficient. The documentation must specify what was different and why the difference was chosen.</li>
<li>The environmental variation should test the conditions most likely to affect the result. If the original experiment was run on idle hardware, the variation should test under load. If it was run in summer, test in winter. The variation should target the most plausible confounds.</li>
<li>If the result holds across environmental variations, the finding's confidence is strengthened. If it does not, the finding is condition-dependent, and the conditions under which it holds must be specified in the knowledge registry entry.</li>
</ul>

<p><strong>Method 4: Documentation Replication.</strong></p>
<p>The operator re-executes the experimental procedure using only the documentation, at least 30 days after the original investigation, without consulting memory. This method primarily tests the quality of the documentation but also provides a secondary data point for the finding itself.</p>
<p>Standards for documentation replication:</p>
<ul>
<li>The operator must follow the written procedure exactly, without deviation. If the procedure is ambiguous or incomplete, the ambiguity or gap is noted as a documentation deficiency (to be corrected) and the replication continues with the operator's best interpretation, documented.</li>
<li>If the documentation is sufficient to produce the same result, both the finding's confidence and the documentation's quality are affirmed. If not, determine whether the failure is due to documentation insufficiency or to a genuine non-replication of the result.</li>
</ul>

<h3>4.2 Replication Success and Failure Criteria</h3>
<p>A replication is classified as successful, partially successful, or failed based on the degree of agreement between the original and replication results:</p>
<p><strong>Successful replication:</strong> The replication produces results that are consistent with the original within the expected variation range. "Consistent" means that the same qualitative conclusion is reached and that any quantitative differences are within the measurement uncertainty or expected environmental variation. A successful replication strengthens the confidence classification of the original finding.</p>
<p><strong>Partial replication:</strong> The replication produces results that partially agree with the original. Some aspects of the finding are confirmed while others are not, or the finding holds under some conditions but not others. Partial replication does not strengthen the original classification but refines the finding by specifying the conditions under which it holds. The knowledge registry entry must be updated to reflect the conditional nature of the finding.</p>
<p><strong>Failed replication:</strong> The replication produces results that clearly contradict the original finding. A failed replication does not automatically invalidate the original -- it indicates a discrepancy that must be investigated. The investigation should address: was the replication procedure faithful to the original? Were conditions different? Could the original result have been a statistical anomaly? Could the replication have introduced new errors? The resolution may downgrade the original finding, may identify condition-specific factors, or may require a third investigation to break the tie.</p>

<h3>4.3 The Replication Record</h3>
<p>Every replication attempt produces a Replication Record (RR) containing:</p>
<ul>
<li><strong>RR ID:</strong> Format RR-YYYY-NNN.</li>
<li><strong>Original experiment reference:</strong> The experiment log ID of the original investigation.</li>
<li><strong>Replication method:</strong> Temporal, Methodological, Environmental, or Documentation.</li>
<li><strong>Date of replication:</strong> When the replication was conducted.</li>
<li><strong>Interval since original:</strong> Time elapsed since the original investigation.</li>
<li><strong>Conditions comparison:</strong> Documented differences between original and replication conditions.</li>
<li><strong>Results comparison:</strong> Side-by-side comparison of original and replication results.</li>
<li><strong>Classification:</strong> Successful, Partial, or Failed, with justification.</li>
<li><strong>Impact on confidence level:</strong> How the replication result affects the original finding's classification in the knowledge registry.</li>
<li><strong>Discrepancy analysis:</strong> If partial or failed, analysis of why the results differed.</li>
<li><strong>Documentation quality assessment:</strong> For documentation replications, an assessment of whether the procedure documentation was sufficient.</li>
</ul>

<h3>4.4 Replication Scheduling</h3>
<p>Not all findings require replication on the same schedule. The prioritization of replication attempts is based on the operational importance of the finding and the confidence level sought:</p>
<ul>
<li><strong>High priority:</strong> Findings that support critical operational decisions (e.g., backup reliability, hardware failure rates, security-related conclusions). These should be replicated within 12 months of initial classification, using at least two different replication methods.</li>
<li><strong>Standard priority:</strong> Findings that inform non-critical operational decisions or strategic planning. These should be replicated within 24 months, using at least one replication method.</li>
<li><strong>Low priority:</strong> Findings that are informational but do not directly drive operational decisions. These may be replicated opportunistically or during scheduled review cycles.</li>
</ul>
<p>The Annual Research Plan (D14-007) should include a replication schedule that identifies which findings are due for replication and allocates research time accordingly. Replication work draws from Pool 1 (Mission-Critical) or Pool 2 (Strategic) depending on the priority of the finding being replicated.</p>
</section>

<section>
<h2>Rules &amp; Constraints</h2>

<ul>
<li><strong>R-REP-01:</strong> No finding may be classified as "verified" in the knowledge registry (D14-004) without at least one successful replication through an adapted replication method. This is a hard prerequisite. Findings that have not been replicated remain "provisional" regardless of how compelling the original evidence appears.</li>
<li><strong>R-REP-02:</strong> Replication attempts must follow the full experimental methodology of D14-002, including pre-registration and experiment log completion. A replication is an experiment and must meet the same documentation standards.</li>
<li><strong>R-REP-03:</strong> Replication failures must be documented with the same rigor as replication successes. A failed replication is not a failed experiment -- it is a finding that the original result does not replicate under the tested conditions. Failed replications must be recorded in the Replication Record and may trigger entries in the Negative Results Registry (D14-005).</li>
<li><strong>R-REP-04:</strong> Temporal replications must observe a minimum interval of 6 months from the original investigation. The operator must follow the documented procedure, not memory.</li>
<li><strong>R-REP-05:</strong> Methodological variations must use genuinely different methods, not minor parameter changes. The pre-registration must justify why the alternative method is a valid test of the same question.</li>
<li><strong>R-REP-06:</strong> If two replication attempts of the same finding produce conflicting results (one successful, one failed), the finding may not be classified as "verified" until the discrepancy is resolved through a third investigation or a detailed analysis of why the results differed.</li>
<li><strong>R-REP-07:</strong> High-priority findings (those supporting critical operational decisions) must be replicated within 12 months of initial classification. The replication schedule must be tracked in the Annual Research Plan.</li>
</ul>
</section>

<section>
<h2>Failure Modes</h2>

<ul>
<li><strong>Replication avoidance.</strong> The operator considers replication a waste of time because they are confident in the original result. Unreplicated findings are classified as "verified" in violation of R-REP-01. Mitigation: the knowledge classification system (D14-004) and the validation process (D14-009) both require replication evidence for "verified" classification. The annual classification audit should verify that all "verified" entries have corresponding Replication Records.</li>
<li><strong>Shallow replication.</strong> The operator performs a nominal replication that does not genuinely test the original finding. They re-run the experiment under identical conditions, observe the same result (which is expected since nothing has changed), and declare the finding replicated. Mitigation: the replication methods require meaningful variation (temporal, methodological, environmental, or documentation-based). A replication under identical conditions by the same operator at the same time is not a replication -- it is a repetition.</li>
<li><strong>Replication failure denial.</strong> The replication produces a different result, but the operator rationalizes the difference as irrelevant rather than investigating it. "The result was close enough" or "the conditions were slightly different" becomes a basis for ignoring the discrepancy. Mitigation: R-REP-03 requires documentation of failures. R-REP-06 prevents verification when results conflict. The Replication Record format forces explicit discrepancy analysis.</li>
<li><strong>Replication scheduling drift.</strong> The replication schedule in the Annual Research Plan is not followed. High-priority replications are deferred repeatedly. Mitigation: R-REP-07 establishes a 12-month deadline for high-priority replications. The quarterly ARP review should check replication schedule compliance.</li>
<li><strong>Documentation insufficiency revealed.</strong> Documentation replications fail not because the finding is wrong but because the documentation is insufficient to reproduce the procedure. This is a documentation problem, not a replication problem, but it can mask genuine non-replications. Mitigation: the Replication Record distinguishes between documentation failures and result failures. Documentation insufficiency triggers procedure documentation improvement, not finding downgrade.</li>
</ul>
</section>

<section>
<h2>Recovery Procedures</h2>

<ol>
<li><strong>If findings have been classified as "verified" without replication:</strong> Conduct a classification audit. Downgrade all unreplicated "verified" findings to "provisional." Schedule replications for the most operationally important findings first. Accept that the institution may have been operating on overconfident knowledge and assess whether any operational decisions need to be reconsidered.</li>
<li><strong>If replications have been shallow or perfunctory:</strong> Identify which replications used genuinely different methods or conditions and which were merely repetitions. Reclassify the latter as unreplicated. Schedule genuine replications using the methods defined in Section 4.1.</li>
<li><strong>If a replication failure has been discovered and ignored:</strong> Reopen the finding. Conduct the discrepancy analysis that should have been done originally. If the discrepancy cannot be resolved, downgrade the finding to "provisional" and flag it for a third investigation.</li>
<li><strong>If the replication schedule has fallen behind:</strong> Review the current schedule. Identify the highest-priority outstanding replications. Allocate dedicated research time in the next quarter to catch up. If the backlog is too large to clear in one quarter, prioritize by operational importance and accept that lower-priority replications may be deferred further.</li>
<li><strong>If documentation replications consistently fail due to documentation quality:</strong> This is a documentation crisis, not a replication crisis. Prioritize documentation improvement for the affected procedures. Re-run documentation replications after the documentation has been improved. Consider whether documentation quality standards in D14-002 need to be strengthened.</li>
</ol>
</section>

<section>
<h2>Evolution Path</h2>

<ul>
<li><strong>Years 0-5:</strong> The first replications are being conducted. The operator is learning what constitutes a genuine replication versus a mere repetition. The 6-month minimum for temporal replication means the first replication results will not arrive until well into the second year. Early findings will remain "provisional" for longer than the operator might prefer. This is by design.</li>
<li><strong>Years 5-15:</strong> A body of replicated findings is accumulating. The institution can begin to assess its replication rate: what fraction of findings replicate successfully? If the rate is very high, the research methodology is robust (or the replications are not genuinely independent). If the rate is low, the methodology may need improvement. Either way, the data is informative.</li>
<li><strong>Years 15-30:</strong> If succession occurs, the successor can conduct the most independent replications the institution has ever experienced. A different person, with different biases and skills, reproducing the predecessor's results, is closer to genuine independent replication than any adapted method available to a single operator. This makes the post-succession period a uniquely valuable window for replication.</li>
<li><strong>Years 30-50+:</strong> The Replication Record archive spans decades. It provides evidence of the institution's intellectual integrity: did it replicate its own findings? Did it take replication failures seriously? Did it honestly acknowledge the limitations of adapted replication? This record is part of the institution's scientific legacy.</li>
</ul>
</section>

<section>
<h2>Founder Commentary</h2>

<p><em>This section is reserved for dated entries by current and future operators.</em></p>
<p><strong>2026-02-17 -- Founding Entry:</strong>
Replication feels like doing the same work twice. It is not. It is doing different work that tests whether the first work was right. The distinction matters because it changes how I approach the replication: not as a chore to confirm what I already believe, but as a genuine test that might produce a different answer.</p>
<p>I am most interested in methodological variation as a replication strategy. If I tested backup reliability by running backups and checking them, and then I test backup reliability by deliberately corrupting data and measuring recovery success, and both methods agree that the backups are reliable, I have much stronger evidence than if I simply ran the same backup test twice. The agreement of two different methods tells me something that no single method, repeated any number of times, can tell me.</p>
<p>I am most worried about replication avoidance. The temptation will be strong: I already tested this, I know it works, why waste time testing it again? The answer is that I do not know it works -- I observed it working once, under specific conditions, measured by one method, interpreted by one biased observer. That is not knowledge. It is a preliminary observation. Replication is what converts it from observation to knowledge. I must remember this when the temptation hits.</p>
</section>

<section>
<h2>Internal References</h2>

<ul>
<li>ETH-001 -- Ethical Foundations (Principle 6: Honest Accounting of Limitations)</li>
<li>CON-001 -- The Founding Mandate (knowledge reliability, institutional continuity)</li>
<li>D14-001 -- Research Philosophy (Section 4.3: adapted replication methods; R-RES-04: adversarial review)</li>
<li>D14-002 -- Experimental Design (methodology for replication experiments)</li>
<li>D14-004 -- Knowledge Classification (confidence levels, "verified" requires replication)</li>
<li>D14-005 -- Negative Results Registry (replication failures as negative results)</li>
<li>D14-007 -- Research Prioritization (replication scheduling in Annual Research Plan)</li>
<li>D14-008 -- Data Integrity in Research (data integrity for replication data)</li>
<li>D14-009 -- Peer Review and Validation (replication as validation method)</li>
</ul>
<hr />
<hr />
</section>
</article>
</main>
</body>
</html>